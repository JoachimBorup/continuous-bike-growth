{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '../csv_data/08-12/'\n",
    "disconnect_pairs = \"continuous_disconnected_pairs\"\n",
    "subgraph_percentages_tests = [\n",
    "    [0.6, 0.4],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.75, 0.25],\n",
    "    [0.25, 0.75],\n",
    "    [0.33, 0.33, 0.34],\n",
    "]\n",
    "prune_quantiles = [0.25, 0.5, 0.75, 1]\n",
    "\n",
    "order = []\n",
    "for subgraph_percentage in subgraph_percentages_tests:\n",
    "    order.append('_'.join(map(str, subgraph_percentage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measureDict = {}\n",
    "file_names = []\n",
    "for file_name in os.listdir(source_folder):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_names.append(file_name)\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Split the file name into parts\n",
    "    parts = file_name.split('_')\n",
    "    city = parts[0]  # The first part is the city\n",
    "    measure = parts[1]  # The second part is the measure\n",
    "        \n",
    "    # The rest are the percentiles (everything from the third element up to '.csv')\n",
    "    percentiles = '_'.join(parts[2:]).replace('.csv', '')\n",
    "    df = pd.read_csv(os.path.join(source_folder, file_name))\n",
    "    df['percentile'] = percentiles  \n",
    "    if measure not in measureDict:\n",
    "        measureDict[measure] = [df]\n",
    "    else:\n",
    "        measureDict[measure].append(df)\n",
    "\n",
    "for k,v in measureDict.items():\n",
    "    print(k)\n",
    "    print(len(v))\n",
    "\n",
    "measureDict[\"random\"][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for measure in measureDict:\n",
    "    mergedPercentileDf = pd.concat(measureDict[measure])\n",
    "    mergedPercentileDf['mean_error'] = mergedPercentileDf.groupby('percentile')['sum_of_errors'].transform('mean')\n",
    "    mergedPercentileDf['mean_disconnected_pairs'] = mergedPercentileDf.groupby('percentile')[disconnect_pairs].transform('mean')\n",
    "\n",
    "    mergedPercentileDf[\"percentile\"] = pd.Categorical(\n",
    "    mergedPercentileDf[\"percentile\"],\n",
    "    categories=order,\n",
    "    ordered=True\n",
    ")\n",
    "    # Create a figure and axes\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot bar chart for mean_error\n",
    "    # order bars by percentile\n",
    "\n",
    "    sns.barplot(\n",
    "        data=mergedPercentileDf,\n",
    "        x=\"percentile\",\n",
    "        y=\"mean_error\",\n",
    "        ax=ax1,\n",
    "        hue=\"percentile\",\n",
    "    )\n",
    "    ax1.set_ylabel(\"Mean Error\", fontsize=12)\n",
    "    ax1.set_xlabel(\"Percentile\", fontsize=12)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=10)\n",
    "\n",
    "    # Add a secondary y-axis for mean_disconnected_pairs\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Calculate mean_disconnected_pairs for each percentile\n",
    "    mean_disconnected = (\n",
    "        mergedPercentileDf.groupby(\"percentile\")[\"mean_disconnected_pairs\"].mean()\n",
    "    )\n",
    "\n",
    "    # Plot points on top of bars\n",
    "    sns.scatterplot(\n",
    "        x=mean_disconnected.index,\n",
    "        y=mean_disconnected.values,\n",
    "        ax=ax2,\n",
    "        color=\"red\",\n",
    "        s=100,\n",
    "        label=\"Avg. Disconnected Pairs\",\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    ax2.set_ylabel(\"Avg. Disconnected Pairs\", fontsize=12, color=\"black\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"black\", labelsize=10)\n",
    "\n",
    "    # Improve layout\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    ax1.set_title(measure+\": Mean Error and Disconnected Pairs by Percentile \", fontsize=14)\n",
    "\n",
    "    # Add legend for the scatter points\n",
    "    ax2.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \n",
    "for measure in measureDict:\n",
    "    mergedPercentileDf = pd.concat(measureDict[measure])\n",
    "    mergedPercentileDf['mean_error'] = mergedPercentileDf.groupby('percentile')['sum_of_errors'].transform('mean')\n",
    "    mergedPercentileDf['mean_disconnected_pairs'] = mergedPercentileDf.groupby('percentile')[disconnect_pairs].transform('mean')\n",
    "    mergedPercentileDf[\"percentile\"] = pd.Categorical(\n",
    "    mergedPercentileDf[\"percentile\"],\n",
    "    categories=order,\n",
    "    ordered=True\n",
    ")\n",
    "    # add line for mean_disconnected_pairs with different y-axis\n",
    "\n",
    "    sns.catplot(data=mergedPercentileDf, kind=\"bar\", y=\"mean_error\", hue=\"percentile\", errorbar=None).set_axis_labels(measure, \"Mean error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meantestdf = pd.read_csv(source_folder + \"copenhagen_betweenness_0.33_0.33_0.34.csv\")\n",
    "print(df[\"sum_of_errors\"].value_counts())\n",
    "\n",
    "#get mean\n",
    "mean = meantestdf['sum_of_errors'].mean()\n",
    "print(\"sanity check that betweeness 0.33_0.33_0.34 mean is in ballpark: \", mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = meantestdf.copy()\n",
    "dftest = dftest[dftest[\"prune_quantile\"] == 0.5]\n",
    "numberofrows = dftest.shape[0]  \n",
    "print(\"number of rows in copenhagen_betweenness_0.33_0.33_0.34.csv where prune_quantile is 0.5: \", numberofrows)\n",
    "print(meantestdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_custom_bins(data, num_bins=10, method=\"equal\"):\n",
    "#     if method == \"equal\":\n",
    "#         # Equal-width bins\n",
    "#         min_val, max_val = data.min(), data.max()\n",
    "#         bins = np.linspace(min_val, max_val, num_bins + 1)\n",
    "#     elif method == \"quantile\":\n",
    "#         # Equal-count bins\n",
    "#         bins = np.quantile(data, np.linspace(0, 1, num_bins + 1))\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid method. Choose 'equal' or 'quantile'.\")\n",
    "#     return bins\n",
    "\n",
    "def erros_vs_discon_points(df, measure, string_p, prune_quantile=0.5):\n",
    "    # Bin the data\n",
    "    bins = 10  # Number of bins\n",
    "    df[\"error_bin\"] = pd.cut(df[\"sum_of_errors\"], bins=bins)\n",
    "    \n",
    "    # Aggregate disconnected pairs per bin\n",
    "    binned_data = df.groupby(\"error_bin\", observed=True,).agg(avg_disconnected=(disconnect_pairs, \"mean\"), bin_center=(\"sum_of_errors\", \"mean\"),).reset_index()\n",
    "\n",
    "    # Sort the original data for histogram\n",
    "    df_sorted = df.sort_values(\"sum_of_errors\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the histogram of sum_of_errors on the primary y-axis\n",
    "    sns.histplot(df_sorted[\"sum_of_errors\"], bins=bins, alpha=0.5, ax=ax1, label=\"Histogram of Errors\")\n",
    "    ax1.set_xlabel(\"Sum of Errors\")\n",
    "    ax1.set_ylabel(\"Frequency of Errors\", color=\"black\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "\n",
    "    # Create a secondary y-axis for disconnected points per bin\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        binned_data[\"bin_center\"], \n",
    "        binned_data[\"avg_disconnected\"], \n",
    "        marker=\"o\", \n",
    "        label=\"Avg. Disconnected Pairs\", \n",
    "        color=\"blue\"\n",
    "    )\n",
    "    ax2.set_ylabel(\"Avg. Disconnected Pairs\", color=\"black\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # Add legend\n",
    "    ax1.legend(loc=\"upper left\", fontsize=10)\n",
    "    ax2.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "    plt.title(\"Disconnected Points vs. Histogram of Sum of Errors with \" + str(measure) + \" and \" + string_p + \" Prune Quantile: \" + str(prune_quantile)) \n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    # save the plot\n",
    "    plt.savefig(\"plots/Disconnected_Points_vs._Histogram_of_Sum_of_Errors with/\" + str(measure) + \" and \" + string_p + \" Prune Quantile: \" + str(prune_quantile) + \".png\")\n",
    "    print(\"plot saved for \" + str(measure) + \" and \" + string_p + \" Prune Quantile: \" + str(prune_quantile))\n",
    "    plt.close()\n",
    "# d = meantestdf.copy()\n",
    "\n",
    "# print(\"d: \" + str(d[\"sum_of_errors\"].value_counts()))\n",
    "# df =d[d[\"prune_quantile\"] == 0.5].copy()\n",
    "# #print count unique values in column\n",
    "# print(\"df: \" + str(df[\"sum_of_errors\"].value_counts()))\n",
    "# df.head()\n",
    "# #erros_vs_discon_points(df=df, measure=\"Betweenness\", string_p=\"0.33_0.33_0.34\", prune_quantile=0.5)\n",
    "# # df[\"error_bin\"] = pd.cut(df[\"sum_of_errors\"], bins=10)\n",
    "# # df.head()\n",
    "# # print(df[\"sum_of_errors\"].describe())\n",
    "# # print(df[\"error_bin\"].value_counts())\n",
    "# #df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in measureDict:\n",
    "    for df in measureDict[measure]:\n",
    "        percentile = df[\"percentile\"][0]\n",
    "        for prune_quantile in prune_quantiles:\n",
    "            #print (measure, percentile, prune_quantile)\n",
    "            pruned = df[df[\"prune_quantile\"] == prune_quantile].copy()\n",
    "            erros_vs_discon_points(df=pruned, measure=measure, string_p=percentile, prune_quantile=prune_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(measureDict[\"betweenness\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(df):\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Correlation Heatmap of Variables\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def change_strings_to_numbers(df):\n",
    "    #show 20 first rows\n",
    "    #map measure to a number \n",
    "    #df['measure'] = df['measure'].map({'betweenness': 1, 'closeness': 2, 'random': 3,})\n",
    "\n",
    "#map percentile to a number\n",
    "    df['percentile'] = df['percentile'].map({'0.75_0.25': 1,'_0.25_0.75':2, '0.25_0.25_0.25_0.25': 3, '0.33_0.33_0.34': 4,})\n",
    "    return df\n",
    "heatdf = pd.concat(measureDict[\"betweenness\"])\n",
    "#remove unessesary columns: bikengrowth_disconnected_pairs,continuous_abstract_edges,bikengrowth_abstract_edges\n",
    "heatdf = heatdf.drop(columns=['bikengrowth_disconnected_pairs','continuous_abstract_edges','bikengrowth_abstract_edges', 'bikengrowth_vertices','percentile' ])\n",
    "heatmap(heatdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation of 0.85 suggests a strong positive relationship.\n",
    "A correlation of -0.75 indicates a strong negative relationship.\n",
    "A correlation near 0 implies no linear dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def density_bell_error(df, percentile):\n",
    "    sns.displot(data=df, x=\"sum_of_errors\", hue=\"prune_quantile\", kind=\"kde\", fill=True)\n",
    "    plt.title(\"Density Plot of Sum of Errors by prune quantile for percentile: \" + percentile)\n",
    "    plt.show()\n",
    "density_bell_error(meantestdf, \"0.33_0.33_0.34\")\n",
    "\n",
    "for measure in measureDict:\n",
    "    mergedPercentileDf = pd.concat(measureDict[measure])\n",
    "    for percentile in order:\n",
    "        density_bell_error(mergedPercentileDf, percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denisity_bell_errors_hue_percentile(df, measure, prune_quantile):\n",
    "    sns.displot(data=df, x=\"sum_of_errors\", hue=\"percentile\", kind=\"kde\", fill=True)\n",
    "    plt.title(\"Density Plot of Sum of Errors by percentile with \" + measure + \" and prune_quantile: \" + str(prune_quantile))\n",
    "    plt.show()\n",
    "    \n",
    "for measure in measureDict:\n",
    "    mergedPercentileDf = pd.concat(measureDict[measure])\n",
    "    for prune_quantile in prune_quantiles :\n",
    "        mdf = mergedPercentileDf.copy()\n",
    "        df = mdf[mdf[\"prune_quantile\"] == prune_quantile]\n",
    "        denisity_bell_errors_hue_percentile(df, measure, prune_quantile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_bell_disconnected(df, percentile):\n",
    "    sns.displot(data=df, x=disconnect_pairs, hue=\"prune_quantile\", kind=\"kde\", fill=True)\n",
    "    plt.title(\"Density Plot of Disconnected Pairs by prune quantile for percentile: \" + percentile)\n",
    "    plt.show()\n",
    "density_bell_disconnected(meantestdf, \"0.33_0.33_0.34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=grouped, x=\"sum_of_errors\", hue=\"measure\", kind=\"kde\", fill=True)\n",
    "plt.title(\"Density Plot of Sum of Errors by Percentile\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
