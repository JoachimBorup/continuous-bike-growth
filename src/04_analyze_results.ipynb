{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Analysis of bicycle network results\n",
    "## Project: Growing Urban Bicycle Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the existing infrastructure, the results from 03_poi_based_generation and calculates/analyzes a number of measures:\n",
    "* cost (length)\n",
    "* coverage  \n",
    "* directness  \n",
    "* efficiency\n",
    "* overlap with existing networks\n",
    "\n",
    "Contact: Michael Szell (michael.szell@gmail.com)  \n",
    "Created: 2020-07-08  \n",
    "Last modified: 2024-09-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "rerun_existing = False # If True, will re-run the costly analysis of existing infra even if files already exist.\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "if not debug: # Only do this if sure the code is bug-free!\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze existing infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    print(placeid + \": Analyzing existing infrastructure.\")\n",
    "    \n",
    "    # output_place is one static file for the existing city. This can be compared to the generated infrastructure.\n",
    "    # Make a check if this file was already generated - it only needs to be done once. If not, generate it:\n",
    "    filename = placeid + \"_existing.csv\"\n",
    "    if rerun_existing or not os.path.isfile(PATH[\"results\"] + placeid + \"/\" + filename):\n",
    "        empty_metrics = {\n",
    "                         \"length\":0,\n",
    "                         \"length_lcc\":0,\n",
    "                         \"coverage\": 0,\n",
    "                         \"directness\": 0,\n",
    "                         \"directness_lcc\": 0,\n",
    "                         \"poi_coverage\": 0,\n",
    "                         \"components\": 0,\n",
    "                         \"efficiency_global\": 0,\n",
    "                         \"efficiency_local\": 0,\n",
    "                         \"efficiency_global_routed\": 0,\n",
    "                         \"efficiency_local_routed\": 0,\n",
    "                         \"directness_lcc_linkwise\": 0,\n",
    "                         \"directness_all_linkwise\": 0\n",
    "                        }\n",
    "        output_place = {}\n",
    "        for networktype in networktypes:\n",
    "            output_place[networktype] = copy.deepcopy(empty_metrics)\n",
    "\n",
    "        # Analyze all networks     \n",
    "        Gs = {}\n",
    "        for networktype in networktypes:\n",
    "            try:\n",
    "                if networktype != \"biketrack_onstreet\" and networktype != \"bikeable_offstreet\":\n",
    "                    Gs[networktype] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype)\n",
    "                    Gs[networktype + \"_simplified\"] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype + \"_simplified\")\n",
    "                elif networktype == \"biketrack_onstreet\":\n",
    "                    Gs[networktype] = intersect_igraphs(Gs[\"biketrack\"], Gs[\"carall\"])\n",
    "                    Gs[networktype + \"_simplified\"] = intersect_igraphs(Gs[\"biketrack_simplified\"], Gs[\"carall_simplified\"])\n",
    "                elif networktype == \"bikeable_offstreet\":\n",
    "                    G_temp = copy.deepcopy(Gs[\"bikeable\"])\n",
    "                    delete_overlaps(G_temp, Gs[\"carall\"])\n",
    "                    Gs[networktype] = G_temp\n",
    "                    G_temp = copy.deepcopy(Gs[\"bikeable_simplified\"])\n",
    "                    delete_overlaps(G_temp, Gs[\"carall_simplified\"])\n",
    "                    Gs[networktype + \"_simplified\"] = G_temp\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        with open(PATH[\"data\"] + placeid + \"/\" + placeid + '_poi_' + poi_source + '_nnidscarall.csv') as f:\n",
    "            nnids = [int(line.rstrip()) for line in f]\n",
    "\n",
    "            \n",
    "        covs = {}\n",
    "        for networktype in tqdm(networktypes, desc = \"Networks\", leave = False):\n",
    "            if debug: print(placeid + \": Analyzing results: \" + networktype)\n",
    "            try:\n",
    "                metrics, cov = calculate_metrics(Gs[networktype], Gs[networktype + \"_simplified\"], Gs['carall'], nnids, empty_metrics, buffer_walk, numnodepairs, debug)\n",
    "                for key, val in metrics.items():\n",
    "                    output_place[networktype][key] = val\n",
    "                covs[networktype] = cov\n",
    "            except:\n",
    "                print(networktype + \" is empty\")\n",
    "        # Save the covers\n",
    "        write_result(covs, \"pickle\", placeid, \"\", \"\", \"existing_covers.pickle\")\n",
    "        \n",
    "        # Write to CSV\n",
    "        write_result(output_place, \"dictnested\", placeid, \"\", \"\", \"existing.csv\", empty_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze POI based results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    print(placeid + \": Analyzing results\")\n",
    "\n",
    "    # Load networks\n",
    "    G_carall = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'carall')\n",
    "    Gexisting = {}\n",
    "    for networktype in [\"biketrack\", \"bikeable\"]:\n",
    "        try:\n",
    "            Gexisting[networktype] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype)\n",
    "        except:\n",
    "            print(networktype + \" is empty\")\n",
    "        \n",
    "    \n",
    "    # Load POIs\n",
    "    with open(PATH[\"data\"] + placeid + \"/\" + placeid + '_poi_' + poi_source + '_nnidscarall.csv') as f:\n",
    "        nnids = [int(line.rstrip()) for line in f]\n",
    "            \n",
    "    # Load results\n",
    "    filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure\n",
    "    resultfile = open(PATH[\"results\"] + placeid + \"/\" + filename + \".pickle\",'rb')\n",
    "    res = pickle.load(resultfile)\n",
    "    resultfile.close()\n",
    "    if debug: pp.pprint(res)\n",
    "         \n",
    "    # Calculate\n",
    "    # output contains lists for all the prune_quantile values of the corresponding results\n",
    "    output, covs = calculate_metrics_additively(res[\"GTs\"], res[\"GT_abstracts\"], res[\"prune_quantiles\"], G_carall, nnids, buffer_walk, numnodepairs, debug, True, Gexisting)\n",
    "    output_MST, cov_MST = calculate_metrics(res[\"MST\"], res[\"MST_abstract\"], G_carall, nnids, output, buffer_walk, numnodepairs, debug, True, ig.Graph(), Polygon(), False, Gexisting)\n",
    "        \n",
    "    # Save the covers\n",
    "    write_result(covs, \"pickle\", placeid, poi_source, prune_measure, \"_covers.pickle\")\n",
    "#     write_result(covs_carminusbike, \"pickle\", placeid, poi_source, prune_measure, \"_covers_carminusbike.pickle\")\n",
    "    write_result(cov_MST, \"pickle\", placeid, poi_source, prune_measure, \"_cover_mst.pickle\")\n",
    "        \n",
    "    # Write to CSV\n",
    "    write_result(output, \"dict\", placeid, poi_source, prune_measure, \".csv\")\n",
    "#     write_result(output_carminusbike, \"dict\", placeid, poi_source, prune_measure, \"_carminusbike.csv\")\n",
    "#     write_result(output_carconstrictedbike, \"dict\", placeid, poi_source, prune_measure, \"_carconstrictedbike.csv\")\n",
    "    write_result(output_MST, \"dict\", placeid, poi_source, \"\", \"mst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file, autoplay=True) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
